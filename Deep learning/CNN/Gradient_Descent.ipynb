{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent Algorithm in Machine Learning\n",
    "\n",
    "* change in y and change in x that is called know as a gradient descent \n",
    "\n",
    "* it is fundamental optimization technique to minimize the cost function of a model by iteratively adjusting the model parameters to **reduce the difference between predicted and actual values, improving the model’s performance.** Let’s see it’s role in machine learning\n",
    "\n",
    "\n",
    "**Vanishing and Exploding Gradients**\n",
    "Vanishing and exploding gradients are common problems that can occur during the training of deep neural networks. These problems can significantly slow down the training process or even prevent the network from learning altogether.\n",
    "\n",
    "\n",
    "* The vanishing gradient problem occurs when gradients become too small during backpropagation. The weights of the network are not considerably changed as a result, and the network is unable to discover the underlying patterns in the data. Many-layered deep neural networks are especially prone to this issue. The gradient values fall exponentially as they move backward through the layers, making it challenging to efficiently update the weights in the earlier layers.\n",
    "\n",
    "The exploding gradient problem, on the other hand, occurs when gradients become too large during backpropagation. When this happens, the weights are updated by a large amount, which can cause the network to diverge or oscillate, making it difficult to converge to a good solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Size \n",
    "when we are pass first traning data in a neural network then that is called know as a batch size  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterations \n",
    "iteration is the number of batch needed to complete one epoch "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Epochs\n",
    "if the one iteration was completed then that is called know as epochs \n",
    "\n",
    "a complete pass through a training dataset\n",
    "\n",
    "\n",
    "\n",
    "#### Choosing the Right Number of Epochs:\n",
    "* Too few epochs → Model may underfit (not learn enough).\n",
    "* Too many epochs → Model may overfit (memorize training data but perform poorly on new data).\n",
    "* A common approach is to use early stopping, where training stops when validation performance stops improving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
