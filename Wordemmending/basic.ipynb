{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word2Vec is a neural network-based model used in Natural Language Processing (NLP) to represent words as continuous numerical vectors (embeddings) in a way that captures their semantic meaning. These word embeddings are dense, low-dimensional representations where similar words are located close to each other in the vector space.\n",
    "\n",
    "Key Concepts of Word2Vec\n",
    "Word Embeddings\n",
    "\n",
    "Words are converted into vectors of fixed size (e.g., 300 dimensions).\n",
    "These vectors encode semantic and syntactic relationships.\n",
    "Example: In a Word2Vec model, vectors for words like \"king\" and \"queen\" might have similar patterns or relationships.\n",
    "Core Training Algorithms\n",
    "Word2Vec uses two main algorithms for training:\n",
    "\n",
    "CBOW (Continuous Bag of Words):\n",
    "Predicts a target word based on its surrounding context words.\n",
    "Efficient for large datasets.\n",
    "Skip-Gram:\n",
    "Predicts the context words given a target word.\n",
    "Performs better for capturing rare words.\n",
    "Context Window\n",
    "\n",
    "Defines how many words to look at around the target word.\n",
    "A small window focuses on local context; a large window captures more global meaning.\n",
    "Advantages of Word2Vec\n",
    "Semantic Relationships: Encodes semantic and syntactic relationships, e.g., \n",
    "vec(\"king\")\n",
    "−\n",
    "vec(\"man\")\n",
    "+\n",
    "vec(\"woman\")\n",
    "≈\n",
    "vec(\"queen\")\n",
    "vec(\"king\")−vec(\"man\")+vec(\"woman\")≈vec(\"queen\").\n",
    "Efficient: Computationally efficient using techniques like negative sampling and hierarchical softmax.\n",
    "Versatile: Useful for many NLP tasks, such as text classification, clustering, and recommendation.\n",
    "Applications of Word2Vec\n",
    "Sentiment Analysis: Representing words in sentiment-based tasks.\n",
    "Machine Translation: Finding word similarities across languages.\n",
    "Recommendation Systems: Using word embeddings for item similarity.\n",
    "Information Retrieval: Semantic search and query expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# word 2 vector "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
